{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Function to obtain corrected copy number based on purity and plody estimate ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "def logr2tumcn(cellularity, total_ploidy, logR):\n",
    "\treturn (((total_ploidy*(2**logR)) - 2*(1-cellularity)) / cellularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## First obtain purity and ploidy estimates (from a copy number caller such as BATTENBERG) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "cellularity = 1\n",
    "total_ploidy = 2.0\n",
    "logR = 1.50419 #log2\n",
    "print(logr2tumcn(cellularity, total_ploidy, logR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "purity_dict = {} #keep track of sample purity\n",
    "ploidy_dict = {} #keep track of sample ploidy\n",
    "\n",
    "#first record Battenberg purity and ploidy\n",
    "df = pd.read_csv(\"/data/khandekara2/dev/Sherlock-Lung/sherlock_lung_final_wgs_1217.txt\", sep=\"\\t\")\n",
    "for s,n, purity, ploidy in zip(list(df[\"Tumor_File\"]), list(df[\"Normal_File\"]), list(df[\"Tumor_Purity\"]), list(df[\"Tumor_Ploidy\"])):\n",
    "    if not pd.isna(s) and not pd.isna(n):\n",
    "        if s.split(\"/\")[-2].startswith(\"v\"):\n",
    "            sample = s.split(\"/\")[-3]\n",
    "        else:\n",
    "            sample=s.split(\"/\")[-2]\n",
    "        purity_dict[sample] = float(purity)\n",
    "        ploidy_dict[sample] = float(ploidy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Run CNVkit (version 0.9.9, example command for one sample) to segment genome (Circular Binary Segmentation) ##\n",
    "**Note this has already been done for all samples**\n",
    "\n",
    "**Results can be found here: /data/Sherlock_Lung/Analysis_results/Azhar/CNVkit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "# /data/khandekara2/bin/anaconda3/envs/cnvkit/bin/python /data/khandekara2/bin/anaconda3/bin/cnvkit.py batch /data/ITEB_Lung_WGS/FireCloud_downloads/Paper2/NCI_75N_DCEG_NSLC_Shipment1_Batch2_124samples/NSLC-AJOC-TTP1-A-1-1-D-A79I-36/v1/NSLC-AJOC-TTP1-A-1-1-D-A79I-36.cram -m wgs --fasta /data/khandekara2/bin/AmpliconArchitect/data_repo/GRCh38/GCA_000001405.15_GRCh38_no_alt_analysis_set.fa -p 24 -d /data/khandekara2/dev/Sherlock-Lung/results/ecDNA/cnvkit-tumor-normal2/NSLC-AJOC-TTP1-A-1-1-D-A79I-36_cnvkit_output/ --normal /data/ITEB_Lung_WGS/FireCloud_downloads/Paper2/ncicontract_dceg_nslc_wgs_datadelivery_aug2019_619samples/RS122271/v1/RS122271.cram  \n",
    "# /data/khandekara2/bin/anaconda3/envs/cnvkit/bin/python /data/khandekara2/bin/anaconda3/bin/cnvkit.py segment /data/khandekara2/dev/Sherlock-Lung/results/ecDNA/cnvkit-tumor-normal2/NSLC-AJOC-TTP1-A-1-1-D-A79I-36_cnvkit_output/NSLC-AJOC-TTP1-A-1-1-D-A79I-36.cnr  -p 24 -m cbs -o /data/khandekara2/dev/Sherlock-Lung/results/ecDNA/cnvkit-tumor-normal2/NSLC-AJOC-TTP1-A-1-1-D-A79I-36_cnvkit_output/NSLC-AJOC-TTP1-A-1-1-D-A79I-36.cns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Rescale CNV calls and obtain corrected TCN estimate and then submit swarm job to run AA pipeline ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"/data/khandekara2/dev/Sherlock-Lung/sherlock_lung_final_wgs_1217.txt\", sep=\"\\t\") #metadata file\n",
    "mapping = dict(zip(df2[\"Tumor_Sample_ID\"], df2[\"Study\"]))\n",
    "df2.set_index(\"Tumor_Sample_ID\", inplace = True)\n",
    "\n",
    "\n",
    "#here you can find the original seeds from CNVkit as well as the \"corrected\" seeds\n",
    "os.chdir(\"/scratch/zhangt8/Azhar/CNVkit\")\n",
    "\n",
    "\n",
    "#INPUTS: logR for a given segment, estimated tumor purity and ploidy for the sample\n",
    "#OUTPUTS: total copy number for the segment\n",
    "with open(\"/scratch/zhangt8/Azhar/AA.rescaled.swarm\", \"w\") as f2:\n",
    "    #now go through all .cns files from CNVkit (these contain the logR estimates)\n",
    "\tfor file in os.listdir(\".\"):\n",
    "\t\tif file.endswith(\".cns\"):\n",
    "\t\t\ts = file.split(\".\")[0]\n",
    "\t\t\tif s in mapping:\n",
    "\t\t\t\tprint(s)\n",
    "                #write new CNV segment file which contains corrected total copy number\n",
    "\t\t\t\twith open(file, 'r') as f, open(s + \".rescaled.CN.bed\", \"w\") as csvout:\n",
    "\t\t\t\t\twriter = csv.writer(csvout, delimiter=\"\\t\")\n",
    "\t\t\t\t\tnext(f)\n",
    "\t\t\t\t\tfor line in f:\n",
    "\t\t\t\t\t\tline = line.rstrip().split(\"\\t\")\n",
    "\t\t\t\t\t\tlog2 = float(line[4])\n",
    "\t\t\t\t\t\tif s in purity_dict and s in ploidy_dict:\n",
    "\t\t\t\t\t\t\tcellularity = purity_dict[s]\n",
    "\t\t\t\t\t\t\ttotal_ploidy = ploidy_dict[s]\n",
    "\t\t\t\t\t\t\ty = logr2tumcn(cellularity, total_ploidy, log2) #rescaled(corrected) total copy number \n",
    "\t\t\t\t\t\t\twriter.writerow([line[0], line[1], line[2], y])   \n",
    "\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\tprint(s)\n",
    "\t\t\t\tsample = s\n",
    "\t\t\t\ts = df2.loc[s, \"Tumor_File\"]\n",
    "\t\t\t\t#print(sample, s)\n",
    "\t\t\t\tf2.write(\"module load samtools/1.15 && export REF_PATH=/data/Sherlock_Lung/Share/Reference/hg38/cache/%2s/%2s/%s && \" + \"/data/khandekara2/bin/PrepareAA/PrepareAA.py -s \" + sample + \" --ref GRCh38 -t 24 --sorted_bam \" + s + \" --cnv_bed /scratch/zhangt8/Azhar/CNVkit/\" + sample + \".rescaled.CN.bed \" + \"--python3_path /data/khandekara2/bin/anaconda3/envs/cnvkit/bin/python --output_directory /scratch/zhangt8/Azhar/results --downsample 40 --run_AA --run_AC\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "##### IMPORTANT: Parameters that have been changed from default based on extensive testing: #\n",
    "\n",
    "* --AA_insert_sdevs 9.0 DEFAULT: 3.0 Rationale: Sequencing libraries with fragment length distributions that have high variance need to have a higher cutoff for standard deviations above/below expected in order to call a structural variant\n",
    "\n",
    "* --cngain 10  DEFAULT: 4.5 Rationale: Copy number calls that have already been corrected for purity and ploidy need to have a higher CN cutoff to be considered putative ecDNA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Here is an example command to run the entire pipeline for one sample ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "/data/khandekara2/bin/PrepareAA/PrepareAA.py -s SB806762 --ref GRCh38 -t 24 --cnv_bed /scratch/zhangt8/Azhar/CNVkit/SB806762.rescaled.CN.bed --sorted_bam /data/ITEB_Lung_WGS/FireCloud_downloads/Paper3/13Nov_835samples/SB806762/v1/SB806762.cram --python3_path /data/khandekara2/bin/anaconda3/envs/cnvkit/bin/python --output_directory /scratch/zhangt8/Azhar/results --AA_insert_sdevs 9.0 --cngain 10 --run_AA --run_AC "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Command to submit SWARM job ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "swarm -f /data/Sherlock_Lung/Analysis_results/AA.rescaled.swarm -g 6 -t 32 --module R/4.0,samtools --logdir logs/ --time 72:00:00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## All output results can be found here ##\n",
    "\n",
    "*/data/Sherlock_Lung/Analysis_results/Azhar/rescaled5*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0
   },
   "version": "0.24.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
